{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5JSady/C1A1fV4MsVptiZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffedox/pbr/blob/main/text_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "iEK3E0bYVHGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Libraries"
      ],
      "metadata": {
        "id": "mFzPULZhVIxF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VzWK0k09YoG4"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In case there are problems with NLTK ->\n",
        "# !pip install -U nltk "
      ],
      "metadata": {
        "id": "1GNAztkr7Kvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmgOBHqhPUB",
        "outputId": "8c49f9ea-62e7-4e6e-b7b6-6dac801b7199"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Merging the extracted parallel corpora"
      ],
      "metadata": {
        "id": "f7si2DrzVQuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`path = os.getcwd()` sets the variable `path` to the current working directory using the `os.getcwd()` method."
      ],
      "metadata": {
        "id": "rgCG6L-ZWH1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "`files = os.listdir(path)` sets the variable `files` to a list of all the files and directories in the current working directory, which is stored in the variable `path`."
      ],
      "metadata": {
        "id": "8G82DuJSWhy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.getcwd()\n",
        "files = os.listdir(path)\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBM0go3gY4xu",
        "outputId": "a259a7db-7758-4e72-ed4f-728f89dee44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'parallel_corpus_vg_en_it_3.xlsx',\n",
              " 'drive',\n",
              " 'parallel_corpus_vg_en_it_5.xlsx',\n",
              " 'parallel_corpus_vg_en_it_19.xlsx',\n",
              " 'parallel_corpus_vg_en_it_12.xlsx',\n",
              " 'parallel_corpus_vg_en_it_13.xlsx',\n",
              " 'parallel_corpus_vg_en_it_18.xlsx',\n",
              " 'parallel_corpus_vg_en_it_10.xlsx',\n",
              " 'parallel_corpus_vg_en_it_16.xlsx',\n",
              " 'parallel_corpus_vg_en_it_15.xlsx',\n",
              " 'parallel_corpus_vg_en_it_8.xlsx',\n",
              " 'parallel_corpus_vg_en_it_20.xlsx',\n",
              " 'parallel_corpus_vg_en_it_9.xlsx',\n",
              " 'parallel_corpus_vg_en_it_14.xlsx',\n",
              " 'parallel_corpus_vg_en_it_2.xlsx',\n",
              " 'parallel_corpus_vg_en_it_11.xlsx',\n",
              " 'parallel_corpus_vg_en_it_1.xlsx',\n",
              " 'parallel_corpus_vg_en_it_7.xlsx',\n",
              " 'parallel_corpus_vg_en_it_21.xlsx',\n",
              " 'parallel_corpus_vg_en_it_4.xlsx',\n",
              " 'parallel_corpus_vg_en_it_17.xlsx',\n",
              " 'parallel_corpus_vg_en_it_6.xlsx',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This list comprehension creates a new list `files_xlsx` that contains all the elements from the `files` list that end with `.xlsx`."
      ],
      "metadata": {
        "id": "TGBk1jMTWjo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files_xlsx = [f for f in files if f[-4:] == 'xlsx']\n",
        "files_xlsx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZvOvjw8Y9ko",
        "outputId": "042213a7-c816-41a4-da25-477c3ba18478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['parallel_corpus_vg_en_it_3.xlsx',\n",
              " 'parallel_corpus_vg_en_it_5.xlsx',\n",
              " 'parallel_corpus_vg_en_it_19.xlsx',\n",
              " 'parallel_corpus_vg_en_it_12.xlsx',\n",
              " 'parallel_corpus_vg_en_it_13.xlsx',\n",
              " 'parallel_corpus_vg_en_it_18.xlsx',\n",
              " 'parallel_corpus_vg_en_it_10.xlsx',\n",
              " 'parallel_corpus_vg_en_it_16.xlsx',\n",
              " 'parallel_corpus_vg_en_it_15.xlsx',\n",
              " 'parallel_corpus_vg_en_it_8.xlsx',\n",
              " 'parallel_corpus_vg_en_it_20.xlsx',\n",
              " 'parallel_corpus_vg_en_it_9.xlsx',\n",
              " 'parallel_corpus_vg_en_it_14.xlsx',\n",
              " 'parallel_corpus_vg_en_it_2.xlsx',\n",
              " 'parallel_corpus_vg_en_it_11.xlsx',\n",
              " 'parallel_corpus_vg_en_it_1.xlsx',\n",
              " 'parallel_corpus_vg_en_it_7.xlsx',\n",
              " 'parallel_corpus_vg_en_it_21.xlsx',\n",
              " 'parallel_corpus_vg_en_it_4.xlsx',\n",
              " 'parallel_corpus_vg_en_it_17.xlsx',\n",
              " 'parallel_corpus_vg_en_it_6.xlsx']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an empty DataFrame using the `pandas` library."
      ],
      "metadata": {
        "id": "PLuq7Hr2Wxet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()"
      ],
      "metadata": {
        "id": "-NeHd81AZCMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looping over all the elements in the `files_xlsx` list and combining their data into a single DataFrame."
      ],
      "metadata": {
        "id": "boQU8fv5W1bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for f in files_xlsx:\n",
        "    data = pd.read_excel(f, index_col=0)\n",
        "    df = df.append(data)"
      ],
      "metadata": {
        "id": "eTdl1lXLZFNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing"
      ],
      "metadata": {
        "id": "ChidZ_UsVVYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `drop_duplicates()` method from the `pandas` library to remove duplicate rows."
      ],
      "metadata": {
        "id": "2CfrYDMOVXNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "cQyrVpRkZwso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing all newline characters in the 'en' and 'it' columns of the DataFrame `df` with a whitespace."
      ],
      "metadata": {
        "id": "mMx9TeTpXT_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['en'] = df['en'].apply(lambda x: re.sub('\\n', ' ', str(x))) \n",
        "df['it'] = df['it'].apply(lambda x: re.sub('\\n', ' ', str(x)))"
      ],
      "metadata": {
        "id": "05PBDyuUcCR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing all special characters except punctuation and accented letters from the 'en' and 'it' columns of the DataFrame `df`."
      ],
      "metadata": {
        "id": "3ILUtqjDXVda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['en'] = df['en'].apply(lambda x: re.sub(r'[^ \\nA-Za-z0-9À-ÖØ-öø-ÿ\\/\\-.,;:\"\\']+', '', str(x))) \n",
        "df['it'] = df['it'].apply(lambda x: re.sub(r'[^ \\nA-Za-z0-9À-ÖØ-öø-ÿ\\/\\-.,;:\"\\']+', '', str(x)))"
      ],
      "metadata": {
        "id": "KZpStyuSfWa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the text and counting the tokens of the 'en' and 'it' columns of the DataFrame `df`."
      ],
      "metadata": {
        "id": "T-_mCw-oXXLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized_text_en'] = df['en'].apply(word_tokenize) \n",
        "df['token_count_en'] = df['tokenized_text_en'].apply(lambda x: len(x))\n",
        "\n",
        "df['tokenized_text_it'] = df['it'].apply(word_tokenize) \n",
        "df['token_count_it'] = df['tokenized_text_it'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "eQd9T7zXgvJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering the DataFrame `df` to only keep the rows where the number of tokens in the 'token_count_en' column is greater than or equal to 6."
      ],
      "metadata": {
        "id": "AOwyf_OaXYeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[(df['token_count_en'] >= 6)]"
      ],
      "metadata": {
        "id": "AFLD5ygkhM_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new column named 'difference', which represents the absolute difference between the number of tokens in the 'token_count_en' and 'token_count_it' columns, and then filtering the DataFrame to only keep the rows where the difference is less than 10."
      ],
      "metadata": {
        "id": "g-uR5kBWXY-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['difference'] = df[\"token_count_en\"] - df[\"token_count_it\"]\n",
        "df['difference'] = df['difference'].abs()\n",
        "df = df[(df['difference'] < 10)]"
      ],
      "metadata": {
        "id": "14DtfY2ojVOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resetting the index of the DataFrame. The `drop` argument is set to `True`, which means that the old index values are discarded and not added as a new column to the DataFrame."
      ],
      "metadata": {
        "id": "IR5XJjIpZKQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QvlZm6mhY8vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Counting the tokens"
      ],
      "metadata": {
        "id": "K3fArB6jYx0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the sum of the values in the 'token_count_en' and 'token_count_it' columns of the DataFrame and assigning the results to the variables `total_tokens_en` and `total_tokens_it`, respectively."
      ],
      "metadata": {
        "id": "Cl_MJ08nY1xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens_en = df['token_count_en'].sum()\n",
        "total_tokens_it = df['token_count_it'].sum()"
      ],
      "metadata": {
        "id": "TC0pqQ0ZZYN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_tokens_en)"
      ],
      "metadata": {
        "id": "ZgVSxYFYZslS",
        "outputId": "f63654c6-376b-4a91-845f-8f52901f46c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "259354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_tokens_it)"
      ],
      "metadata": {
        "id": "uiA_PO7RZt0T",
        "outputId": "9717b1b4-e87a-4327-c15b-91e4a03190cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Exporting to Excel"
      ],
      "metadata": {
        "id": "JPuHDd_lY5p_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing the content of the DataFrame to an Excel spreadsheet named 'parallel_corpus.xlsx'."
      ],
      "metadata": {
        "id": "C9hzsl1EZazC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('parallel_corpus.xlsx')  "
      ],
      "metadata": {
        "id": "N-IBMhCcaaLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}