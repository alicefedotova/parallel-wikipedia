# A semi-automatic approach to parallel corpora extraction from the Wikipedia

This repository contains the software developed for the pilot project of the Profession-Based Research course. The main task of the project was to identify in-domain Wikipedia articles in English and Italian in order to extract a parallel corpus.

## Contents

1. Parallel_corpus_creation.ipynb
2. Report


https://stackoverflow.com/questions/53101673/get-all-pages-from-a-given-category-from-wikipedia

https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html

https://arxiv.org/pdf/1907.05791.pdf

https://www.statmt.org/wmt22/pdf/2022.wmt-1.38.pdf

https://arxiv.org/abs/1908.10084

https://towardsdatascience.com/cutting-edge-bert-nlp-model-bb0bfc8b7aec

distiluse-base-multilingual-cased > LASER
